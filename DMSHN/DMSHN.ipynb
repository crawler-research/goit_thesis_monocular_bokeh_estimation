{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DMSHN model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        #Conv1\n",
    "        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "            )\n",
    "        #Conv2\n",
    "        self.layer5 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            )\n",
    "        #Conv3\n",
    "        self.layer9 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Conv1\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x) + x\n",
    "        x = self.layer3(x) + x\n",
    "        #Conv2\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x) + x\n",
    "        x = self.layer7(x) + x\n",
    "        #Conv3\n",
    "        x = self.layer9(x)    \n",
    "        x = self.layer10(x) + x\n",
    "        x = self.layer11(x) + x \n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()        \n",
    "        # Deconv3\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer14 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer16 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n",
    "        #Deconv2\n",
    "        self.layer17 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer18 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer20 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "        #Deconv1\n",
    "        self.layer21 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer22 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "            )\n",
    "        self.layer24 = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self,x):        \n",
    "        #Deconv3\n",
    "        x = self.layer13(x) + x\n",
    "        x = self.layer14(x) + x\n",
    "        x = self.layer16(x)                \n",
    "        #Deconv2\n",
    "        x = self.layer17(x) + x\n",
    "        x = self.layer18(x) + x\n",
    "        x = self.layer20(x)\n",
    "        #Deconv1\n",
    "        x = self.layer21(x) + x\n",
    "        x = self.layer22(x) + x\n",
    "        x = self.layer24(x)\n",
    "        return x\n",
    "\n",
    "class DMSHN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DMSHN, self).__init__()\n",
    "        self.encoder_lv1 = Encoder()\n",
    "        self.encoder_lv2 = Encoder()\n",
    "        self.encoder_lv3 = Encoder()\n",
    "\n",
    "        self.decoder_lv1 = Decoder()\n",
    "        self.decoder_lv2 = Decoder()\n",
    "        self.decoder_lv3 = Decoder()\n",
    "\n",
    "    def forward(self,images_lv1):\n",
    "        H = images_lv1.size(2)\n",
    "        W = images_lv1.size(3)\n",
    "\n",
    "        images_lv2 = F.interpolate(images_lv1, scale_factor = 0.5, mode = 'bilinear')\n",
    "        images_lv3 = F.interpolate(images_lv2, scale_factor = 0.5, mode = 'bilinear')\n",
    "\n",
    "        feature_lv3 = self.encoder_lv3(images_lv3)\n",
    "        residual_lv3 = self.decoder_lv3(feature_lv3)\n",
    "        out_lv3 = images_lv3 + residual_lv3 \n",
    "\n",
    "        residual_lv3 = F.interpolate(residual_lv3, scale_factor=2, mode= 'bilinear')\n",
    "        feature_lv3 = F.interpolate(feature_lv3, scale_factor=2, mode= 'bilinear')\n",
    "        feature_lv2 = self.encoder_lv2(images_lv2 + residual_lv3)\n",
    "        residual_lv2 = self.decoder_lv2(feature_lv2 + feature_lv3)\n",
    "        out_lv2 = images_lv2 + residual_lv2\n",
    "\n",
    "        residual_lv2 = F.interpolate(residual_lv2, scale_factor=2, mode= 'bilinear')\n",
    "        feature_lv2 = F.interpolate(feature_lv2, scale_factor=2, mode= 'bilinear')\n",
    "        feature_lv1 = self.encoder_lv1(images_lv1 + residual_lv2)\n",
    "        bokeh_image = self.decoder_lv1(feature_lv1 + feature_lv2)\n",
    "\n",
    "\n",
    "        return bokeh_image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked DMSHN model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacked_DMSHN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(stacked_DMSHN,self).__init__()\n",
    "        self.net1 = DMSHN()\n",
    "        self.net2 = DMSHN()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out1 = self.net1(x)\n",
    "        out2 = self.net2(out1)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Stacked DMSHN on sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7b/dxvk6ctn7yzgkzt7ccsrrtgh0000gn/T/ipykernel_45275/1622802200.py:58: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  input_image = input_image.resize((feed_width, feed_height), pil.LANCZOS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import PIL.Image as pil\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import numbers\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "feed_width = 1536\n",
    "feed_height = 1024\n",
    "\n",
    "\n",
    "bokehnet = stacked_DMSHN().to(device)\n",
    "bokehnet = nn.DataParallel(bokehnet)\n",
    "\n",
    "bokehnet.load_state_dict(torch.load('checkpoints/SDMSHN/sdmshn.pth',map_location=device))\n",
    "\n",
    "\n",
    "os.makedirs('sample_outputs',exist_ok= True)\n",
    "\n",
    "src_dir  = 'sample_inputs/'\n",
    "listfiles = os.listdir(src_dir)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for file in listfiles : \n",
    "\n",
    "        image_path = src_dir + file\n",
    "\n",
    "        # Load image and preprocess\n",
    "        input_image = pil.open(image_path).convert('RGB')\n",
    "        original_width, original_height = input_image.size\n",
    "\n",
    "        input_image = input_image.resize((feed_width, feed_height), pil.LANCZOS)\n",
    "        input_image = transforms.ToTensor()(input_image).unsqueeze(0)\n",
    "\n",
    "        # PREDICTION\n",
    "        input_image = input_image.to(device)\n",
    "\n",
    "        bok_pred = bokehnet(input_image)\n",
    "\n",
    "        bok_pred = F.interpolate(bok_pred,(original_height,original_width),mode = 'bilinear')\n",
    "        \n",
    "        \n",
    "        save_image(bok_pred,'./sample_outputs/'+ file )\n",
    "\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/var/folders/7b/dxvk6ctn7yzgkzt7ccsrrtgh0000gn/T/ipykernel_45275/3360143231.py:43: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  total_ssim += compare_ssim(I0,I1,multichannel=True)\n",
      "100%|██████████| 4/4 [00:03<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(1,'PerceptualSimilarity')\n",
    "# import models\n",
    "from util import util\n",
    "\n",
    "## Initializing the model\n",
    "# model = models.PerceptualLoss(model='net-lin',net='alex',use_gpu=opt.use_gpu)\n",
    "\n",
    "# crawl directories\n",
    "files = os.listdir('sample_inputs')\n",
    "\n",
    "# total_dist = 0\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "\n",
    "for file in tqdm(files):\n",
    "\tfile1 = file[:4] + '.jpg'\n",
    "\tif(os.path.exists(os.path.join(\"sample_inputs\",file1))):\n",
    "\t\t# Load images\n",
    "\t\timg0 = util.im2tensor(util.load_image(os.path.join(\"sample_inputs\",file))) # RGB image from [-1,1]\n",
    "\t\timg1 = util.im2tensor(util.load_image(os.path.join(\"sample_outputs\",file1)))\n",
    "\n",
    "\t\t# if(opt.use_gpu):\n",
    "\t\t# \timg0 = img0.cuda()\n",
    "\t\t# \timg1 = img1.cuda()\n",
    "\n",
    "\t\t# Compute distance\n",
    "\t\t# dist01 = model.forward(img0,img1)\n",
    "\t\t# total_dist += dist01.item()\n",
    "\n",
    "\t\tI0 = cv2.imread(os.path.join(\"sample_inputs\",file))\n",
    "\t\tI1 = cv2.imread(os.path.join(\"sample_outputs\",file1))\n",
    "\t\ttotal_psnr += compare_psnr(I0,I1)\n",
    "\t\ttotal_ssim += compare_ssim(I0,I1,multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg PSNR:  24.75821945388755\n",
      "Avg SSIM:  0.7442593146718459\n"
     ]
    }
   ],
   "source": [
    "# print ('Avg LPIPS: ', total_dist/len(files))\n",
    "print ('Avg PSNR: ', total_psnr/len(files))\n",
    "print ('Avg SSIM: ', total_ssim/len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
